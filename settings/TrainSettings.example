PRETRAIN_MODEL_PATH_NAME = ""
#PRETRAIN_MODEL_PATH_NAME = "temp/models/testVali/save_epoch_25/IceNet.ckpt"
NAME_SCOPES_NOT_TO_RECOVER_FROM_CHECKPOINT = []
#NAME_SCOPES_NOT_TO_RECOVER_FROM_CHECKPOINT = ['ResLayer4', 'ResLayer5']

TRAINING_SET_PATH_NAME = "data/train.json"
VALIDATION_RATIO = 0.1
NUMBER_OF_VALIDATION_DATA = 160
BATCH_SIZE = 100

MAX_TRAINING_EPOCH = 100

EPOCHS_TO_START_SAVE_MODEL = 20
PATH_TO_SAVE_MODEL = "temp/models/DarkNet19"
MAX_TRAINING_SAVE_MODEL = MAX_TRAINING_EPOCH

'''
    Following can be used to customize learning rate,
    you can either use tf.train.exponetial_decay().
'''
#LIST_OF_EPOCH_LEARNING_RATE_PAIRS = [ (0, 1e-5) ]
#LIST_OF_EPOCH_LEARNING_RATE_PAIRS = [ (0, 1e-3), (50, 1e-4) ]
LIST_OF_EPOCH_LEARNING_RATE_PAIRS = [ (0, 1e-4), (70, 1e-5) ]
#LIST_OF_EPOCH_LEARNING_RATE_PAIRS = [ (0, 1e-4), (30, 1e-5), (100, 1e-6) ]
def GetLearningRate(currentEpoch_):
	for eachPair in reversed(LIST_OF_EPOCH_LEARNING_RATE_PAIRS):
		if currentEpoch_ >= eachPair[0]:
			return eachPair[1]

	# If nothing matched, return the first pair.learningRate as default
	return trainSettings.LIST_OF_EPOCH_LEARNING_RATE_PAIRS[0][1] 


######################
#  Advanced Settings #
######################
'''
      For Large Model such as VGG16, one can't stuff all validation set
    into one batch.  In this case, you should trun the following variable
    to False.  And the validation loss & accuracy will be calculated
    one by one. (The training will be slower, but the loss & accuracy value
    will be the same.)
'''
DOES_CALCULATE_VALIDATION_SET_AT_ONCE = True
